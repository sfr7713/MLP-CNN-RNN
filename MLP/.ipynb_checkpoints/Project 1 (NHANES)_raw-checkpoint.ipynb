{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1\n",
    "\n",
    "Predicting diabetes using the NHANES dataset\n",
    "\n",
    "About our dataset\n",
    "The National Health and Nutrition Examination Survey (NHANES), administered annually by the National Center for Health Statistics, is designed to assess the general health and nutritional status of adults and children in the United States.\n",
    "\n",
    "\n",
    "Data:\n",
    "\n",
    "https://wwwn.cdc.gov/nchs/nhanes/continuousnhanes/default.aspx?BeginYear=2013\n",
    "\n",
    "\n",
    "Goals:\n",
    "\n",
    "- refresh general machine learning principles (train/dev/test)\n",
    "- refresh neural network implementation\n",
    "- handle an imbalanced dataset\n",
    "\n",
    "Keras:\n",
    "\n",
    "The Python Deep Learning Library Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter notebook supports automated reloading of packages. So once you import a file as a module, any saved changes you make to that file will be automatically changed in this notebook. For example, go to exercise_1.py and toggle the comment the second \"print\" statement in helloworld(), rerunning the next cell several times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exercise_1 import helloworld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helloworld()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing the dataset\n",
    "We provide a helper function for you to read the SAS files into a pandas dataframe. \n",
    "\n",
    "To load it, you will need to install xport (a SAS interface to Python) \n",
    "\n",
    "```pip install xport```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import merge_xpt, get_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODIFY THIS CELL BY POINTING IT TO WHERE YOU EXTRACTED YOUR DATA ###\n",
    "data_root = \"/Users/aashna/Downloads/nhanes\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_training_data(data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two commands above are useful for quickly getting a feel for the dataset. We definitely want to know the shape of the dataframe so we know how many features we're dealing with, and we can see the number of missing values in each column, as well as a few descriptive statistics.\n",
    "\n",
    "# Exercise 1: \n",
    "\n",
    "The Diabetes column is coded as 1.0: yes and 2.0: no, and for some reason there are a few rows with a 3.0. We don't know what 3.0 means, so we will drop it. Also, we will remove all of the samples that have a NaN (for easy training later- also it seems like we'll still have enough data). \n",
    "\n",
    "As most of you are familiar with SQL, these references may be helpful:\n",
    "https://pandas.pydata.org/pandas-docs/stable/comparison_with_sql.html\n",
    "\n",
    "Use it to complete clean_data_and_labels() in exercise_1.py(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exercise_1 import clean_data_and_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_data_and_labels(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to check your code. \n",
    "# If you see no output, you have completed the exercise correctly.\n",
    "assert np.all(df.Diabetes < 3), \"Not all labels are < 3.0\"\n",
    "assert np.all(df.count() == len(df)), \"There are still NaNs in your data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2:\n",
    "\n",
    "With the clean dataset we are ready to build and train the model.\n",
    "\n",
    "Please build your neural network by completing build_model() in exercise_1.py. The architecture choice is up to you, but please only use fully connected (Dense) layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exercise_1 import build_model, split_x_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if the model works. If it runs your model is functioning properly\n",
    "x_sm, y_sm = split_x_y(df[0:10])  # load the first 10 samples\n",
    "model.fit(x_sm, y_sm, batch_size=1, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3:\n",
    "Model tuning\n",
    "\n",
    "Optimize your neural network by modifying the cells below. Here are a few hints:\n",
    "\n",
    "- You are not provided with a validation set, so it may be helpful to make your own. \n",
    "- Check the distribution of the labels using df.Diabetes.hist(). What should you do about this? (make any changes to preprocess_dataset() in exercise_1.py- OPTIONAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from exercise_1 import preprocess_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess_dataset(df)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df.shape[1] == 11, \\\n",
    "\"Number of features is off, make sure you didn't remove or add any\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the cells below to fit your model and as scratch (perhaps to view the dataset distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are happy with your model training, run the below cell to generate the final labels for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_testing_data\n",
    "test_data, _ = get_testing_data(data_root)\n",
    "predicted = model.predict_classes(test_data)\n",
    "with open(\"exercise_1_output.txt\", \"w\") as f:\n",
    "    [f.write(\"{}\\n\".format(p)) for p in predicted]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Exercise 4:\n",
    "(OPTIONAL)\n",
    "\n",
    "Do you find any relationship between Age and whether a person has Diabetes or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Exercise 5:\n",
    "(OPTIONAL)\n",
    "\n",
    "Predict whether the person sleeps for less than mean sleeping hours across the dataset or more?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Exercise 6:\n",
    "(OPTIONAL)\n",
    "\n",
    "Predict the alcohol consumption of the person?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
